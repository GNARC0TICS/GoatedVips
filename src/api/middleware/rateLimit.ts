import { Request, Response, NextFunction } from 'express';\nimport { ICacheService } from '../../infrastructure/cache/ICacheService';\n\n// Rate limit configuration\nexport interface RateLimitConfig {\n  windowMs: number;      // Time window in milliseconds\n  max: number;           // Maximum requests per window\n  keyGenerator?: (req: Request) => string;  // Custom key generator\n  skip?: (req: Request) => boolean;         // Skip rate limiting for certain requests\n  message?: string;      // Custom error message\n  standardHeaders?: boolean;                // Include rate limit headers\n  legacyHeaders?: boolean;                  // Include legacy X-RateLimit headers\n}\n\n// Rate limit store interface\nexport interface RateLimitStore {\n  increment(key: string, windowMs: number): Promise<{ totalRequests: number; remainingTime: number }>;\n  reset(key: string): Promise<void>;\n}\n\n// Redis-based rate limit store\nexport class RedisRateLimitStore implements RateLimitStore {\n  constructor(private cache: ICacheService) {}\n\n  async increment(key: string, windowMs: number): Promise<{ totalRequests: number; remainingTime: number }> {\n    const now = Date.now();\n    const window = Math.floor(now / windowMs);\n    const cacheKey = `ratelimit:${key}:${window}`;\n    \n    try {\n      // Increment counter\n      const count = await this.cache.incr(cacheKey);\n      \n      // Set expiration on first increment\n      if (count === 1) {\n        await this.cache.expire(cacheKey, Math.ceil(windowMs / 1000));\n      }\n      \n      const remainingTime = windowMs - (now % windowMs);\n      \n      return {\n        totalRequests: count,\n        remainingTime\n      };\n    } catch (error) {\n      console.error('Rate limit store error:', error);\n      // Fail open - allow request if rate limiting fails\n      return {\n        totalRequests: 1,\n        remainingTime: windowMs\n      };\n    }\n  }\n\n  async reset(key: string): Promise<void> {\n    try {\n      // Find all keys for this identifier\n      const pattern = `ratelimit:${key}:*`;\n      const keys = await this.cache.keys(pattern);\n      \n      if (keys.length > 0) {\n        await this.cache.mdelete(keys);\n      }\n    } catch (error) {\n      console.error('Rate limit reset error:', error);\n    }\n  }\n}\n\n// Memory-based rate limit store (for development/testing)\nexport class MemoryRateLimitStore implements RateLimitStore {\n  private store = new Map<string, { count: number; resetTime: number }>();\n\n  async increment(key: string, windowMs: number): Promise<{ totalRequests: number; remainingTime: number }> {\n    const now = Date.now();\n    const window = Math.floor(now / windowMs);\n    const storeKey = `${key}:${window}`;\n    \n    let entry = this.store.get(storeKey);\n    \n    if (!entry) {\n      entry = { count: 0, resetTime: (window + 1) * windowMs };\n      this.store.set(storeKey, entry);\n    }\n    \n    entry.count++;\n    \n    // Clean up old entries\n    this.cleanup(now);\n    \n    return {\n      totalRequests: entry.count,\n      remainingTime: entry.resetTime - now\n    };\n  }\n\n  async reset(key: string): Promise<void> {\n    for (const [storeKey] of this.store) {\n      if (storeKey.startsWith(`${key}:`)) {\n        this.store.delete(storeKey);\n      }\n    }\n  }\n\n  private cleanup(now: number): void {\n    // Clean up expired entries (run occasionally)\n    if (Math.random() < 0.01) { // 1% chance\n      for (const [key, entry] of this.store) {\n        if (now > entry.resetTime) {\n          this.store.delete(key);\n        }\n      }\n    }\n  }\n}\n\n// Rate limiting middleware factory\nexport function createRateLimitMiddleware(\n  store: RateLimitStore,\n  defaultConfig: Partial<RateLimitConfig> = {}\n) {\n  return function rateLimitMiddleware(config: RateLimitConfig) {\n    const finalConfig = {\n      windowMs: 15 * 60 * 1000, // 15 minutes\n      max: 100,\n      keyGenerator: (req: Request) => req.ip || 'unknown',\n      message: 'Too many requests, please try again later',\n      standardHeaders: true,\n      legacyHeaders: false,\n      ...defaultConfig,\n      ...config,\n    };\n\n    return async (req: Request, res: Response, next: NextFunction) => {\n      try {\n        // Skip if configured to skip\n        if (finalConfig.skip && finalConfig.skip(req)) {\n          return next();\n        }\n\n        const key = finalConfig.keyGenerator!(req);\n        const result = await store.increment(key, finalConfig.windowMs);\n        \n        const remaining = Math.max(0, finalConfig.max - result.totalRequests);\n        const resetTime = new Date(Date.now() + result.remainingTime);\n        \n        // Add standard headers\n        if (finalConfig.standardHeaders) {\n          res.set({\n            'RateLimit-Limit': finalConfig.max.toString(),\n            'RateLimit-Remaining': remaining.toString(),\n            'RateLimit-Reset': resetTime.toISOString(),\n          });\n        }\n        \n        // Add legacy headers\n        if (finalConfig.legacyHeaders) {\n          res.set({\n            'X-RateLimit-Limit': finalConfig.max.toString(),\n            'X-RateLimit-Remaining': remaining.toString(),\n            'X-RateLimit-Reset': Math.ceil(resetTime.getTime() / 1000).toString(),\n          });\n        }\n        \n        // Check if limit exceeded\n        if (result.totalRequests > finalConfig.max) {\n          return res.status(429).json({\n            success: false,\n            error: finalConfig.message,\n            code: 'RATE_LIMIT_EXCEEDED',\n            retryAfter: Math.ceil(result.remainingTime / 1000),\n            limit: finalConfig.max,\n            remaining: 0,\n            reset: resetTime.toISOString(),\n          });\n        }\n        \n        next();\n      } catch (error) {\n        console.error('Rate limit middleware error:', error);\n        // Fail open - allow request if rate limiting fails\n        next();\n      }\n    };\n  };\n}\n\n// Predefined rate limit configurations\nexport const RateLimitPresets = {\n  // Very strict - for sensitive operations\n  strict: {\n    windowMs: 15 * 60 * 1000, // 15 minutes\n    max: 5,\n  },\n  \n  // Moderate - for authentication\n  auth: {\n    windowMs: 15 * 60 * 1000, // 15 minutes\n    max: 10,\n  },\n  \n  // Standard - for general API use\n  standard: {\n    windowMs: 15 * 60 * 1000, // 15 minutes\n    max: 100,\n  },\n  \n  // Lenient - for public endpoints\n  lenient: {\n    windowMs: 15 * 60 * 1000, // 15 minutes\n    max: 1000,\n  },\n  \n  // Burst - short window, higher limit\n  burst: {\n    windowMs: 60 * 1000, // 1 minute\n    max: 20,\n  },\n};\n\n// Simple rate limit middleware (uses memory store)\nexport function rateLimitMiddleware(config: RateLimitConfig) {\n  const store = new MemoryRateLimitStore();\n  const middleware = createRateLimitMiddleware(store);\n  return middleware(config);\n}\n\n// User-specific rate limiting\nexport function userRateLimitMiddleware(\n  store: RateLimitStore,\n  config: RateLimitConfig\n) {\n  const middleware = createRateLimitMiddleware(store, {\n    keyGenerator: (req: Request) => {\n      // Use user ID if authenticated, otherwise fall back to IP\n      return req.user?.id || req.ip || 'unknown';\n    },\n  });\n  \n  return middleware(config);\n}\n\n// IP-based rate limiting with whitelist\nexport function ipRateLimitMiddleware(\n  store: RateLimitStore,\n  config: RateLimitConfig & { whitelist?: string[] }\n) {\n  const middleware = createRateLimitMiddleware(store, {\n    keyGenerator: (req: Request) => `ip:${req.ip}`,\n    skip: (req: Request) => {\n      return config.whitelist?.includes(req.ip || '') || false;\n    },\n  });\n  \n  return middleware(config);\n}\n\n// Sliding window rate limiter\nexport class SlidingWindowRateLimiter {\n  constructor(\n    private cache: ICacheService,\n    private windowMs: number,\n    private maxRequests: number\n  ) {}\n\n  async isAllowed(key: string): Promise<{ allowed: boolean; remaining: number; resetTime: number }> {\n    const now = Date.now();\n    const windowStart = now - this.windowMs;\n    const cacheKey = `sliding:${key}`;\n    \n    try {\n      // Get existing timestamps\n      const timestamps = await this.cache.lrange(cacheKey, 0, -1) || [];\n      \n      // Filter out expired timestamps\n      const validTimestamps = timestamps\n        .map(ts => parseInt(ts))\n        .filter(ts => ts > windowStart);\n      \n      // Check if under limit\n      const allowed = validTimestamps.length < this.maxRequests;\n      \n      if (allowed) {\n        // Add current timestamp\n        await this.cache.lpush(cacheKey, now.toString());\n        await this.cache.expire(cacheKey, Math.ceil(this.windowMs / 1000));\n      }\n      \n      // Calculate reset time (when oldest request expires)\n      const oldestTimestamp = Math.min(...validTimestamps, now);\n      const resetTime = oldestTimestamp + this.windowMs;\n      \n      return {\n        allowed,\n        remaining: Math.max(0, this.maxRequests - validTimestamps.length - (allowed ? 1 : 0)),\n        resetTime\n      };\n    } catch (error) {\n      console.error('Sliding window rate limiter error:', error);\n      // Fail open\n      return {\n        allowed: true,\n        remaining: this.maxRequests - 1,\n        resetTime: now + this.windowMs\n      };\n    }\n  }\n}"